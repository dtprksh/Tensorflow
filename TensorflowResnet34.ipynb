{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shortcut(x,num_filter):\n",
    "    out=tf.layers.conv2d(x,num_filter,3,use_bias=False)\n",
    "    out=tf.layers.batch_normalization(out)\n",
    "    out=tf.nn.relu(out)\n",
    "    out=tf.layers.conv2d(out,num_filter,3)\n",
    "    out=tf.layers.batch_normalization(out)\n",
    "    out=out+x\n",
    "    out=tf.nn.relu(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transition(x,num_filter):\n",
    "    out=tf.layers.conv2d(x,num_filter,3,strides=2,use_bias=False)\n",
    "    out=tf.layers.batch_normalization(out)\n",
    "    out=tf.nn.relu(out)\n",
    "    out=tf.layers.conv2d(out,num_filter,3)\n",
    "    out=tf.layers.batch_normalization(out)\n",
    "    x=tf.layers.conv2d(x,num_filter,3,strides=2,use_bias=False)\n",
    "    out=out+x\n",
    "    out=tf.nn.relu(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shortcutxn(out,num_filter,n):\n",
    "    for i in range(n):\n",
    "        out=shortcut(out,num_filter)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet(x_dict,n_classes):\n",
    "    x=x_dict['images']\n",
    "    out=tf.layers.conv2d(x,64,7,strides=2,use_bias=False)\n",
    "    out=tf.layers.batch_normalization(out)\n",
    "    out=tf.nn.relu(out)\n",
    "    out=tf.layers.MaxPooling2D(pool_size=2,strides=2)\n",
    "    out=shortcutxn(out,64,3)\n",
    "    out=transition(out,128)\n",
    "    out=shortcutxn(out,128,3)\n",
    "    out=transition(out,256)\n",
    "    out=shortcutxn(out,256,5)\n",
    "    out=transition(out,512)\n",
    "    out=shortcutxn(out,512,2)\n",
    "    out=tf.layers.AveragePooling2D(pool_size=7,strides=1)\n",
    "    out=tf.layers.Flatten()(out)\n",
    "    out=tf.layers.dense(out,10)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(features,labels,mode):\n",
    "    logits_train = resnet(features, num_classes)\n",
    "    logits_test = resnet(features, num_classes)\n",
    "\n",
    "\n",
    "    pred_classes = tf.argmax(logits_test, axis=1)\n",
    "    pred_probas = tf.nn.softmax(logits_test)\n",
    "\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode, predictions=pred_classes)\n",
    "\n",
    "\n",
    "    loss_op = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        logits=logits_train, labels=tf.cast(labels, dtype=tf.int32)))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    train_op = optimizer.minimize(loss_op,\n",
    "                                  global_step=tf.train.get_global_step())\n",
    "\n",
    "\n",
    "    acc_op = tf.metrics.accuracy(labels=labels, predictions=pred_classes)\n",
    "\n",
    "\n",
    "    estim_specs = tf.estimator.EstimatorSpec(\n",
    "        mode=mode,\n",
    "        predictions=pred_classes,\n",
    "        loss=loss_op,\n",
    "        train_op=train_op,\n",
    "        eval_metric_ops={'accuracy': acc_op})\n",
    "\n",
    "    return estim_specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "(x_train,y_train),(x_test,y_test)=cifar10.load_data()\n",
    "import cv2\n",
    "x=[]\n",
    "for i in range(len(x_test)):\n",
    "    x.append(cv2.resize(x_test[i],(224,224)))\n",
    "xte=np.array(x)\n",
    "xte=xte/255.\n",
    "xtr=[]\n",
    "for i in range(len(x_train)):\n",
    "    xtr.append(cv2.resize(x_train[i],(224,224)))\n",
    "xtr=np.array(xtr)\n",
    "xtr=xtr/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_checkpointing_config = tf.estimator.RunConfig(\n",
    "    save_checkpoints_secs = 2*60,  # Save checkpoints every 20 minutes.\n",
    "    keep_checkpoint_max = 10       # Retain the 10 most recent checkpoints.\n",
    ")\n",
    "model = tf.estimator.Estimator(model_fn,model_dir='estimatormodel',config=my_checkpointing_config)\n",
    "\n",
    "# Define the input function for training\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'images': xtr}, y=y_train,\n",
    "    batch_size=batch_size, num_epochs=None, shuffle=True)\n",
    "# Train the Model\n",
    "model.train(input_fn, steps=num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'images': xte}, y=y_test,\n",
    "    batch_size=32, shuffle=False)\n",
    "e = model.evaluate(input_fn)\n",
    "\n",
    "print(\"Testing Accuracy:\", e['accuracy'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
